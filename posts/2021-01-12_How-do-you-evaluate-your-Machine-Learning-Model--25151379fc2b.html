<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>How do you evaluate your Machine Learning Model?</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">How do you evaluate your Machine Learning Model?</h1>
</header>
<section data-field="subtitle" class="p-summary">
Good answers and bad answers
</section>
<section data-field="body" class="e-content">
<section name="dec4" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h4 name="1c19" id="1c19" class="graf graf--h4 graf--leading graf--kicker">Machine Learning for Business</h4><h3 name="2655" id="2655" class="graf graf--h3 graf-after--h4 graf--title">How do you evaluate your Machine Learning Model?</h3><h4 name="174f" id="174f" class="graf graf--h4 graf-after--h3 graf--subtitle">Good answers and bad answers</h4><p name="09f9" id="09f9" class="graf graf--p graf-after--h4">Suppose you use <a href="https://medium.com/on-technology/tagged/machine-learning" data-href="https://medium.com/on-technology/tagged/machine-learning" class="markup--anchor markup--p-anchor" target="_blank">Machine Learning</a> to solve some business problem in your organization. For example, you might run an e-commerce website, where you sell groceries; where customers log in, browse your stock, checkout what they want, pay for it, and then have the goods delivered to them. You (or one of your colleagues) might have built a machine learning model that “recommends” items for your customers, on the home-page of your website.</p><figure name="c62d" id="c62d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WpwCuPLzdbbPlaRK5CXf7g.png" data-width="1066" data-height="353" src="https://cdn-images-1.medium.com/max/800/1*WpwCuPLzdbbPlaRK5CXf7g.png"><figcaption class="imageCaption"><a href="https://www.audible.com" data-href="https://www.audible.com" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://www.audible.com</a></figcaption></figure><p name="d9be" id="d9be" class="graf graf--p graf-after--figure">Now, suppose I asked you,</p><blockquote name="88d2" id="88d2" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“How do you evaluate your Machine Learning Model?”</blockquote><p name="d857" id="d857" class="graf graf--p graf-after--blockquote">I.e. How do you know if it’s good or bad? And if it can be improved? And if other people have better models? I ask this question often, and different people give very different answers: some good, many not so good.</p><p name="cc24" id="cc24" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">This article is a “classification” of possible answers to the question “How do you evaluate your Machine Learning Model?”: From really bad answers to very good ones. Read on to find out if yours is good or bad.</strong></p><h3 name="b78a" id="b78a" class="graf graf--h3 graf-after--p">ML0 — “I don’t.”</h3><p name="f411" id="f411" class="graf graf--p graf-after--h3">Sadly, the most common answer to “How do you evaluate your Machine Learning Model?” is:</p><blockquote name="140a" id="140a" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“I don’t”</blockquote><p name="0df3" id="0df3" class="graf graf--p graf-after--blockquote">Few people know how well their Machine Learning Models work. Not everyone is this honest, though. Many people (especially on the “business side”) say something elaborate, throwing in jargon, and buzzwords, and references to “technology”. They might say something meaningless like:</p><blockquote name="43ae" id="43ae" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“We use the cutting edge HardMacro Turquoise AI Stack, and have a best-in-class e-commerce recommendation paradigm”.</blockquote><p name="c139" id="c139" class="graf graf--p graf-after--blockquote">But it’s fairly easy to see through the “<a href="https://en.wikipedia.org/wiki/Bullshit" data-href="https://en.wikipedia.org/wiki/Bullshit" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">BS</a>”, and that in reality, they have no idea.</p><p name="2ce8" id="2ce8" class="graf graf--p graf-after--p">This “ML0” is the lowest level in my classification, and if you think you fall into this group, I have two pieces of good news:</p><ol class="postList"><li name="91ca" id="91ca" class="graf graf--li graf-after--p">Most organizations fall into this group. They’ve invested significant resources into Machine Learning or Data Analytics, but have no idea of the exact benefit it brings.</li><li name="7376" id="7376" class="graf graf--li graf-after--li">This article explains how you can move up from “ML0” and improve your organization uses Machine Learning.</li></ol><h3 name="5a72" id="5a72" class="graf graf--h3 graf-after--li">ML1 — “Using Anecdotes”</h3><p name="852a" id="852a" class="graf graf--p graf-after--h3">Slightly better than having no idea is to have some idea. Many people have an anecdotal sense of their Machine Learning Systems; based on qualitative feedback from more knowledgeable colleagues or customers, like:</p><blockquote name="1fb4" id="1fb4" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“Our Chief Data Scientists said that the new model is much better than the old one”</blockquote><p name="47e4" id="47e4" class="graf graf--p graf-after--blockquote">Or a customer might say</p><blockquote name="144b" id="144b" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“Oh yes. I use the recommendations on your website all the time. It’s very useful”.</blockquote><h3 name="445a" id="445a" class="graf graf--h3 graf-after--blockquote">ML2 — “Using Technical Metrics”</h3><p name="e6f8" id="e6f8" class="graf graf--p graf-after--h3">You might argue that it is “business people” who are guilty of ML0 and ML1. If you are a “technical person” (say a Machine Learning Engineer), you use all manner of fancy quantitative metrics to describe your ML.</p><p name="36bc" id="36bc" class="graf graf--p graf-after--p">For example, you might say that your e-commerce recommendation has:</p><blockquote name="ff72" id="ff72" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“A <a href="https://en.wikipedia.org/wiki/False_positive_rate" data-href="https://en.wikipedia.org/wiki/False_positive_rate" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">False Positive Rate</a> (FPR) of only 60%”</blockquote><p name="a708" id="a708" class="graf graf--p graf-after--blockquote">In laymen’s terms this usually means “The probability of a recommended item not being purchased by a customer”. Similarly, “<a href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives" data-href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">False Negative Rate</a> (FNR)” means “the probability of not recommending a product that will be purchased by a customer”.</p><p name="2a6c" id="2a6c" class="graf graf--p graf-after--p">On the one hand, having metrics like FPRs and FNRs (ML2) is better than having no idea on how the ML is doing (ML0), or only having a “qualitative” sense (ML1). On the other hand, it has at least three drawbacks:</p><ol class="postList"><li name="3858" id="3858" class="graf graf--li graf--startsWithDoubleQuote graf-after--p">“Technical Metrics” like FPRs and FNRs (and more elaborate metrics like <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" data-href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">ROC curves</a> etc.), have no clear “real-world” meaning. What would an FPR and FNR of 60% and 27.5% mean to the CEO? Would it be better than 70% and 15%?</li><li name="41f1" id="41f1" class="graf graf--li graf-after--li">A comparison of Technical Metrics might not translate into Business Metrics. A model that is better than another model based on technical metrics is not necessarily better than the other model on business metrics.</li><li name="4897" id="4897" class="graf graf--li graf--startsWithDoubleQuote graf-after--li">“Technical Metrics” isolate technical problems and people from the “bigger picture”. For example, your e-commerce recommendation system could also be improved by better design, better photos, and different colours. These changes are not reflected in metrics like ROC, and hence cannot be compared to technical changes like ML improvements.</li></ol><p name="e356" id="e356" class="graf graf--p graf-after--li">Organizations with ML teams that solely rely on Technical Metrics tend to isolate from the broader group working on the problem. “We care about what we measure” or more accurately “We don’t care about what we don’t measure.”</p><h3 name="c4e4" id="c4e4" class="graf graf--h3 graf-after--p">ML3 — “Using Business Metrics”</h3><p name="482a" id="482a" class="graf graf--p graf-after--h3">In the best ML organizations, even the most technical ML teams, measure themselves on Business Metrics, not Technical Metrics. For example, when I used to work on <a href="https://www.facebook.com/business/help/355670007911605?id=561906377587030" data-href="https://www.facebook.com/business/help/355670007911605?id=561906377587030" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Ads Optimization at Facebook</a>, we measured Models that recommend advertisements with metrics such as Revenue, Advertiser Profit, and User Feedback. No one ever mentioned FPRs or ROCs. These might be used operationally, (e.g. to “debug” faulty models), but never as a measure of model performance or quality.</p><p name="b3d4" id="b3d4" class="graf graf--p graf-after--p">Whenever a report or presentation on ML models, gives Technical Metrics priority over Business Metrics (ML2), it usually means one or both of the following:</p><ol class="postList"><li name="c3c0" id="c3c0" class="graf graf--li graf-after--p">The technical team is unaware or unfamiliar with the actual business problem they are trying to solve.</li><li name="7be4" id="7be4" class="graf graf--li graf-after--li">The technical team is trying to misguide or impress the audience by throwing technical metrics and other jargon.</li></ol><h3 name="e57f" id="e57f" class="graf graf--h3 graf-after--li">ML4 — “Using Business Metrics, across the Pipeline”</h3><p name="9696" id="9696" class="graf graf--p graf-after--h3">The best organizations not only use Business Metrics to evaluate ML Models and ML Teams but also use business metrics “operationally”, at a “low level”, say, when optimizing, tuning, and comparing different models.</p><p name="41ea" id="41ea" class="graf graf--p graf-after--p">For example, suppose you have several models for your e-commerce recommendation system: one is based on <a href="https://en.wikipedia.org/wiki/Logistic_regression" data-href="https://en.wikipedia.org/wiki/Logistic_regression" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">logistic regression</a>, another based on <a href="https://en.wikipedia.org/wiki/Boosting_%28machine_learning%29" data-href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">boosting</a>, another based on <a href="https://en.wikipedia.org/wiki/Deep_learning" data-href="https://en.wikipedia.org/wiki/Deep_learning" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">deep neural networks</a>. You could either compare these models on “Technical Metrics” (like FPRs and ROCs) or you could try and compare these using Business Metrics, like Sales or Revenue. The Business Metrics would give you a more robust and accurate measure of which model is better.</p><h3 name="8a92" id="8a92" class="graf graf--h3 graf-after--p">ML5 — “Using <em class="markup--em markup--h3-em">Multiple</em> Business Metrics, across the Pipeline”</h3><p name="eb0b" id="eb0b" class="graf graf--p graf-after--h3">Most non-trivial, real-world problems cannot be measured or evaluated using a single metric (ML4).</p><p name="a897" id="a897" class="graf graf--p graf-after--p">For example, an e-commerce recommendation system, Revenue or Sales alone might not be sufficient. We might want to also look at measures like “Long term value of Customer”, “Time to complete Checkout”, and “Customer Feedback”. If recommendations are for cheap, but low-quality products, we might see a short-term improvement in revenue, but a decline in long-term value.</p><p name="01d2" id="01d2" class="graf graf--p graf-after--p">Hence, we should evaluate ML Models (and all other parts of the system) on all the business metrics that the organization cares about, not just one. In practice, this might involve some tricky comparisons of “<a href="https://en.wikipedia.org/wiki/Apples_and_oranges" data-href="https://en.wikipedia.org/wiki/Apples_and_oranges" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">apples and oranges</a>”. But this is where humans judgement must take charge. The best Machine Learning systems are aides for smart humans, not replacements for dumb ones.</p><figure name="b544" id="b544" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*W3yTIq2SJn9SfQxfxoeHJQ.png" data-width="801" data-height="454" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*W3yTIq2SJn9SfQxfxoeHJQ.png"></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@nuwans" class="p-author h-card">Nuwan I. Senaratna</a> on <a href="https://medium.com/p/25151379fc2b"><time class="dt-published" datetime="2021-01-12T03:22:32.794Z">January 12, 2021</time></a>.</p><p><a href="https://medium.com/@nuwans/how-do-you-evaluate-your-machine-learning-model-25151379fc2b" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 18, 2021.</p></footer></article></body></html>