#### Article 176 · November 25, 2019

# Monkey Business

### 2019 Sri Lanka Presidential Elections

During the lead up to the 2019 Sri Lankan Presidential Election, many tried to predict the outcome. Some even emailed me detailed "analyses" on how they arrived at their conclusions.

Here are predictions from 11 "human" "experts". For clarity, I only include their forecast for the winning SLPP.

![Image](https://cdn-images-1.medium.com/max/800/1*p5Ly1h_BR_rz26kZ8c__hA.png)

Some asked me to "evaluate" their predictions. Had they got it right?

In almost all cases, the key numbers were derived from opinion and assumptions. For example, "80% of SLFP supporters would vote for the SLPP", where the number was not derived from a survey of SLFP supporters, but purely the author's opinion. Hence, it was possible to dismiss analyses purely qualitatively. Without even looking at the numbers.

However, a few analyses came up with predictions reasonably close to the final result. And a couple of the authors sent "Hey! You pooh-poohed me. But I got it right. I'm a genius"-type, self-congratulatory emails.

Now, you might correctly point out that a few "experts" got lucky. But can we prove it? Can we separate the humans from the monkeys?

## The Monkey Test (Part 1)

Can we design a statistical test to answer the question, "Is the expert actually an expert, or a monkey?"

In statistics-speak, "The expert is a monkey" is known as the "Null-Hypothesis". "The expert is an expert" is known as the "Alternative Hypothesis".

The test begins by asking the question, "Could the predictions have come from a bunch of monkeys?"

So, I went off to Dehiwala Zoo. And asked in an assortment of apes to fill in a questionnaire with their predictions. Compensating each participant with a Kolikuttu.

Actually, I made that bit up. The Zoo was closed. And I'm not sure if the apes would have corporated, even for Kolikuttus. So, I "simulated" a monkey.

In On Floating Voters, I speculated that the SLPP should get between 44% and 61% of the vote. So, I wrote a bit of code that randomly picks a number between 44% and 61%.

```
import randomfor i in range(0, 100):   print([0.44 + 0.17 * random.random())
```

The 100 "monkey predictions" were as follows (sorted in increasing order):

![Image](https://cdn-images-1.medium.com/max/800/1*hUT0WDvzv4H0gCcyYxJtJQ.png)

Here are the absolute errors for the predictions.

![Image](https://cdn-images-1.medium.com/max/800/1*Am6duTHIiKj6DfR7MwDjzg.png)

One monkey (red) predicted 52.19% for the SLPP, just 0.6% from the actual 52.25% that the SLPP got. Nine other monkeys (orange), arrived within 1%, and 12 others within 2%.

## The Monkey Test (Part 2)

Now, back to our Null and Alternative Hypotheses.

If a random man claims to be able to predict the election, it is natural to be sceptical. The chances are that he is a monkey. So we bias towards the Null Hypothesis. We ask "What is the probability that what this man says could have been said by a Monkey?". And if this probability is not smaller than a small number (say 5% or 10%), then we conclude that the man is a monkey. In statistics speak, this is called "Hypothesis Testing".

For example, 10 of our 100 monkeys got within 1% of the final result. So, if our random man's predictions are off my more than 1%, we'll have to conclude that he is a monkey. Or more formally, "There is no evidence, at a 10% significance level, to conclude that the man is not a monkey".

So, how did our "experts" do?

![Image](https://cdn-images-1.medium.com/max/800/1*koP9AYS8CPwVa5OokXrslQ.png)

Of our 11 experts, only one predicted within 1% of the final result. Hence, we could conclude that "There is no evidence, at a 10% significance level, to conclude that any of the other 10 are not monkeys".

Actually, 5% significance is more common in statistical analyses than 10%. Hence, we could probably conclude that "There is no evidence, at a 5% significance level, to conclude that any of our experts are not monkeys".

## Concluding suggestions

You might retort, "Can any human expert prove that they are not a monkey? 1% is too hard".

And of course, you're right. It is tough to predict elections accurately. If there was one point I tried to make in my pre-election articles, it was this point. An accurate prediction requires a lot of data and a lot of hard work.

On the other hand, it is quite easy to guess and get lucky. As we saw, some of our monkeys were a lot luckier than many of our experts. Hence, you have to prove that you did not get lucky.

How do you do that?

* Prove that you have data. Like wide-ranging surveys from many people.

* Prove that you have done this in the past, and have got it right.

* Prove that you have #SkinInTheGame. What you have to lose if you get your prediction wrong

![Image](https://cdn-images-1.medium.com/max/800/1*tgf8z6t-jmgbTaZDmGdhMA.jpeg)

Kolikuttu, anyone?