#### Article 24 · December 11, 2018

# On Programming

### What next?

### Programming 1.0 — Writing Textual Code

![Image](https://cdn-images-1.medium.com/max/800/1*xnaWJP9xiKrqnB9zjB1qSA.png)

The first programming language I learnt was BASIC — way back as a teenager. This was followed by Visual Basic, Pascal, C++, C#, Java, Python, PHP and JavaScript. Some languages came and went. Others went, and came back.

Despite this evolution, one thing did not change. The "code" consisted of text in a text file, and the "coding" happened on a text editor. Of course, there were fancy editors and even fancier "Integrated Development Environments" (IDEs). But the simple act of "writing code in text" seemed eternal.

### Programming 1.5 — Meta Programming

![Image](https://cdn-images-1.medium.com/max/800/1*Vj19XDUX6XtKyZwF0NFp9g.png)

Programming 1.0 or writing textual code, still dominates programming on most technology projects. However, there's also an interesting parallel trend — Meta Programming — or writing programmes that write other programs.

The best known type of programming is Supervised Machine Learning [1]. Programmers don't write the final code — instead, write meta programs (Machine Learning Algorithms) that take data and generate the final code based on this. This "final code" is known as a machine learning model, and is used to evaluate further new data.

You might argue that this is still Programming 1.0, with the human programmer writing the Machine Learning Algorithm as textual code. However, there are two important differences.

* The Machine Learning Algorithm can be reused with little modification, for different sets of data. Hence, the Compiled Machine Learning Algorithm (rather like a compiled utility library) remains unchanged, while the Compiled Machine Learning Model changes with the data.

* The actual "heavy lifting" (or processing) is mostly done by the machine generated (or meta programmed) Compiled Machine Learning Model.

I've labelled this meta-programming as 1.5, and not 2.0, because it still relies on 1.0, and is very much a parallel phenomenon, not a replacement.

### Programming 2.0 — Artificial General Intelligence, and the End of Human Programmers

![Image](https://cdn-images-1.medium.com/max/800/0*cpTSzaBZag1sKPWU.jpg)

What if there was a meta program that could learn from any data? And solve any problem? This idea has been referred to as "Artificial General Intelligence".

Artificial General Intelligence [3] is a "meta program" or a Compiled Machine Learning Algorithm that can learn from any data set. Hence, once this is written, there is no need for humans to write any more programs.

There are many doubts and concerns about when and how Artificial general intelligence will come about. I don't have enough original information to contribute meaningfully to this discussion. Instead, let me speculate on what might happen between now (1.5), and Artificial General Intelligence (2.0).

### Programming 1.75 — Or what next?

I wanted to write about, not Machine Learning or AI, but about programming. (For my thoughts on the "what next" in AI, refer to [4]).

How would things be different for programmers and in programming in the next few years?

* Meta Programming Beyond Machine Learning and AI. For everything from User Interface Design, Databases, Server Design, and Computer Networks.

* Minimizing redundant commands in programming languages. What is the minimal number of characters with which a program can be defined? This is all a human needs to type. And the rest can be machine generated. Programs will be shorter.

* Minimizing programmer error. The "boring" aspects of programming will taken over by machines, with humans doing the "creative" aspects. Things like debugging, testing, and quality assurance can be automated away.

* Beyond Text Editors. With "non-redundant" and creativity-optimizing programming languages, the advantages of a keyboard would be minimal. More visual-spatial-tactile interfaces are likely to "inspire" programmers more.

* "Informate" [5] programming. Humans and machines will be programming in parallel. Machines will process less-creative-more-processing-heavy code, while humans will create more-creative-less-processing-heavy code.

### References

[1] https://en.wikipedia.org/wiki/Supervised_learning

[2] https://pixabay.com/en/photos/artificial%20intelligence/?

[3] https://en.wikipedia.org/wiki/Artificial_general_intelligence

[4] https://medium.com/@nuwan.senaratna/the-briefest-history-of-ai-def2a34ab883

[5] http://www.layoftheland.net/archive/web/mis-575/course_docs/topic_5/zuboff.infomate.pdf